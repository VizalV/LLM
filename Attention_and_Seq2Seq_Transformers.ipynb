{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import math\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "jzb39VX3eOVp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Transformer(nn.Module):\n",
        "    def __init__(self, src_vocab_size, tgt_vocab_size, d_model=512, nhead=8,\n",
        "                 num_layers=6, dim_feedforward=2048, dropout=0.1, max_len=5000):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "\n",
        "        # Embedding layers\n",
        "        self.src_embed = nn.Embedding(src_vocab_size, d_model)\n",
        "        self.tgt_embed = nn.Embedding(tgt_vocab_size, d_model)\n",
        "        self.pos_encoder = PositionalEncoding(d_model, dropout, max_len)\n",
        "\n",
        "        # Encoder and Decoder stacks\n",
        "        encoder_layer = TransformerEncoderLayer(d_model, nhead, dim_feedforward, dropout)\n",
        "        self.encoder = TransformerEncoder(encoder_layer, num_layers)\n",
        "\n",
        "        decoder_layer = TransformerDecoderLayer(d_model, nhead, dim_feedforward, dropout)\n",
        "        self.decoder = TransformerDecoder(decoder_layer, num_layers)\n",
        "\n",
        "        # Output layer\n",
        "        self.fc_out = nn.Linear(d_model, tgt_vocab_size)\n",
        "\n",
        "        self._init_weights()\n",
        "\n",
        "    def _init_weights(self):\n",
        "        for p in self.parameters():\n",
        "            if p.dim() > 1:\n",
        "                nn.init.xavier_uniform_(p)\n",
        "\n",
        "    def forward(self, src, tgt, src_mask=None, tgt_mask=None,\n",
        "               src_padding_mask=None, tgt_padding_mask=None):\n",
        "        # Embedding + Positional Encoding\n",
        "        src = self.pos_encoder(self.src_embed(src) * math.sqrt(self.d_model))\n",
        "        tgt = self.pos_encoder(self.tgt_embed(tgt) * math.sqrt(self.d_model))\n",
        "\n",
        "        # Encoder\n",
        "        memory = self.encoder(src, src_mask, src_padding_mask)\n",
        "\n",
        "        # Decoder\n",
        "        output = self.decoder(tgt, memory, tgt_mask, None,\n",
        "                             tgt_padding_mask, src_padding_mask)\n",
        "\n",
        "        return self.fc_out(output)\n",
        "\n",
        "class TransformerEncoderLayer(nn.Module):\n",
        "    def __init__(self, d_model, nhead, dim_feedforward=2048, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.self_attn = nn.MultiheadAttention(d_model, nhead, dropout=dropout)\n",
        "        self.linear1 = nn.Linear(d_model, dim_feedforward)\n",
        "        self.linear2 = nn.Linear(dim_feedforward, d_model)\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.dropout1 = nn.Dropout(dropout)\n",
        "        self.dropout2 = nn.Dropout(dropout)\n",
        "        self.activation = F.relu\n",
        "\n",
        "    def forward(self, src, src_mask=None, src_key_padding_mask=None):\n",
        "        # Self attention\n",
        "        src2 = self.self_attn(\n",
        "            src, src, src,\n",
        "            attn_mask=src_mask,\n",
        "            key_padding_mask=src_key_padding_mask\n",
        "        )[0]\n",
        "        src = src + self.dropout1(src2)\n",
        "        src = self.norm1(src)\n",
        "\n",
        "        # Feedforward\n",
        "        src2 = self.linear2(self.dropout(self.activation(self.linear1(src))))\n",
        "        src = src + self.dropout2(src2)\n",
        "        src = self.norm2(src)\n",
        "        return src\n",
        "\n",
        "class TransformerDecoderLayer(nn.Module):\n",
        "    def __init__(self, d_model, nhead, dim_feedforward=2048, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.self_attn = nn.MultiheadAttention(d_model, nhead, dropout=dropout)\n",
        "        self.multihead_attn = nn.MultiheadAttention(d_model, nhead, dropout=dropout)\n",
        "        self.linear1 = nn.Linear(d_model, dim_feedforward)\n",
        "        self.linear2 = nn.Linear(dim_feedforward, d_model)\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "        self.norm3 = nn.LayerNorm(d_model)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.dropout1 = nn.Dropout(dropout)\n",
        "        self.dropout2 = nn.Dropout(dropout)\n",
        "        self.dropout3 = nn.Dropout(dropout)\n",
        "        self.activation = F.relu\n",
        "\n",
        "    def forward(self, tgt, memory, tgt_mask=None, memory_mask=None,\n",
        "                tgt_key_padding_mask=None, memory_key_padding_mask=None):\n",
        "        # Self attention\n",
        "        tgt2 = self.self_attn(\n",
        "            tgt, tgt, tgt,\n",
        "            attn_mask=tgt_mask,\n",
        "            key_padding_mask=tgt_key_padding_mask\n",
        "        )[0]\n",
        "        tgt = tgt + self.dropout1(tgt2)\n",
        "        tgt = self.norm1(tgt)\n",
        "\n",
        "        # Encoder-decoder attention\n",
        "        tgt2 = self.multihead_attn(\n",
        "            tgt, memory, memory,\n",
        "            attn_mask=memory_mask,\n",
        "            key_padding_mask=memory_key_padding_mask\n",
        "        )[0]\n",
        "        tgt = tgt + self.dropout2(tgt2)\n",
        "        tgt = self.norm2(tgt)\n",
        "\n",
        "        # Feedforward\n",
        "        tgt2 = self.linear2(self.dropout(self.activation(self.linear1(tgt))))\n",
        "        tgt = tgt + self.dropout3(tgt2)\n",
        "        tgt = self.norm3(tgt)\n",
        "        return tgt\n",
        "\n",
        "class TransformerEncoder(nn.Module):\n",
        "    def __init__(self, encoder_layer, num_layers):\n",
        "        super().__init__()\n",
        "        self.layers = nn.ModuleList([encoder_layer for _ in range(num_layers)])\n",
        "\n",
        "    def forward(self, src, src_mask=None, src_key_padding_mask=None):\n",
        "        output = src\n",
        "        for layer in self.layers:\n",
        "            output = layer(output, src_mask, src_key_padding_mask)\n",
        "        return output\n",
        "\n",
        "class TransformerDecoder(nn.Module):\n",
        "    def __init__(self, decoder_layer, num_layers):\n",
        "        super().__init__()\n",
        "        self.layers = nn.ModuleList([decoder_layer for _ in range(num_layers)])\n",
        "\n",
        "    def forward(self, tgt, memory, tgt_mask=None, memory_mask=None,\n",
        "                tgt_key_padding_mask=None, memory_key_padding_mask=None):\n",
        "        output = tgt\n",
        "        for layer in self.layers:\n",
        "            output = layer(\n",
        "                output, memory,\n",
        "                tgt_mask=tgt_mask,\n",
        "                memory_mask=memory_mask,\n",
        "                tgt_key_padding_mask=tgt_key_padding_mask,\n",
        "                memory_key_padding_mask=memory_key_padding_mask\n",
        "            )\n",
        "        return output\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
        "        super().__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        position = torch.arange(max_len).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.pe[:x.size(0), :]\n",
        "        return self.dropout(x)\n",
        "\n",
        "def generate_square_subsequent_mask(sz):\n",
        "    mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
        "    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
        "    return mask\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    # Hyperparameters\n",
        "    src_vocab_size = 100\n",
        "    tgt_vocab_size = 100\n",
        "    d_model = 512\n",
        "    nhead = 8\n",
        "    num_layers = 6\n",
        "    dim_feedforward = 2048\n",
        "    dropout = 0.1\n",
        "\n",
        "    # Create model\n",
        "    model = Transformer(\n",
        "        src_vocab_size=src_vocab_size,\n",
        "        tgt_vocab_size=tgt_vocab_size,\n",
        "        d_model=d_model,\n",
        "        nhead=nhead,\n",
        "        num_layers=num_layers,\n",
        "        dim_feedforward=dim_feedforward,\n",
        "        dropout=dropout\n",
        "    )\n",
        "\n",
        "    # Example forward pass\n",
        "    src = torch.randint(0, src_vocab_size, (1, 10))  # (seq_len, batch_size)\n",
        "    tgt = torch.randint(0, tgt_vocab_size, (2, 10))\n",
        "\n",
        "    tgt_mask = generate_square_subsequent_mask(tgt.size(0))\n",
        "\n",
        "    output = model(src, tgt, tgt_mask=tgt_mask)\n",
        "    print(f\"Output shape: {output.shape}\")  # Should be (tgt_seq_len, batch_size, tgt_vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I6APv34egQH0",
        "outputId": "e1b89091-3aa0-4c46-e8d5-44bfb974482c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output shape: torch.Size([2, 10, 100])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, dropout=0.1, max_len=20):\n",
        "        super().__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        position = torch.arange(max_len).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.pe[:x.size(0), :]\n",
        "        return self.dropout(x)"
      ],
      "metadata": {
        "id": "EB9d8quGeF7b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerModel(nn.Module):\n",
        "    def __init__(self, input_vocab_size, target_vocab_size, d_model=8, nhead=1, num_layers=1, dim_feedforward=16):\n",
        "        super(TransformerModel, self).__init__()\n",
        "        self.d_model = d_model\n",
        "      # Embedding layers\n",
        "        self.input_embedding = nn.Embedding(input_vocab_size, d_model)\n",
        "        self.target_embedding = nn.Embedding(target_vocab_size, d_model)\n",
        "        self.positional_encoding = PositionalEncoding(d_model)\n",
        "        # Transformer\n",
        "        self.transformer = nn.Transformer(\n",
        "            d_model=d_model, nhead=nhead, num_encoder_layers=num_layers,\n",
        "            num_decoder_layers=num_layers, dim_feedforward=dim_feedforward, batch_first=True\n",
        "        )\n",
        "        # Output layer\n",
        "        self.fc_out = nn.Linear(d_model, target_vocab_size)\n",
        "    def generate_square_subsequent_mask(self, sz):\n",
        "        mask = torch.triu(torch.ones(sz, sz) * float('-inf'), diagonal=1)\n",
        "        return mask\n",
        "    def forward(self, src, tgt):\n",
        "        src_mask = None\n",
        "        tgt_mask = self.generate_square_subsequent_mask(tgt.size(1)).to(src.device)\n",
        "        src_emb = self.positional_encoding(self.input_embedding(src) * np.sqrt(self.d_model))\n",
        "        tgt_emb = self.positional_encoding(self.target_embedding(tgt) * np.sqrt(self.d_model))\n",
        "        output = self.transformer(src_emb, tgt_emb, src_mask=src_mask, tgt_mask=tgt_mask)\n",
        "        return self.fc_out(output)"
      ],
      "metadata": {
        "id": "D47HU_mFePza"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A ChatBot"
      ],
      "metadata": {
        "id": "O1DjgGZhFN5R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_texts  =[]\n",
        "target_texts = []\n",
        "with open(\"/content/dialogs.txt\",'r') as f :\n",
        "    for line in f :\n",
        "        line  =  line.split('\\t')\n",
        "        input_texts.append(line[0])\n",
        "        target_texts.append(line[1])\n",
        "print(len(input_texts) == len(target_texts))"
      ],
      "metadata": {
        "id": "jz8TMuWNeQrt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88af4d30-a5f3-418b-a291-bec66834e8d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target_texts[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i9ELqLdF95e4",
        "outputId": "db66709e-d76e-4d92-b7d4-5a260b5a8317"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"i'm fine. how about yourself?\\n\",\n",
              " \"i'm pretty good. thanks for asking.\\n\",\n",
              " 'no problem. so how have you been?\\n',\n",
              " \"i've been great. what about you?\\n\",\n",
              " \"i've been good. i'm in school right now.\\n\"]"
            ]
          },
          "metadata": {},
          "execution_count": 237
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter out the first 100 prompts\n",
        "input_texts = input_texts[:10]\n",
        "target_texts = target_texts[:10]"
      ],
      "metadata": {
        "id": "qSJuRPSBAd3V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "def clean_text(text):\n",
        "       text = re.sub(r\"[^a-zA-Z0-9 ]\", \"\", text)  # Keep only letters, numbers, and spaces\n",
        "       return text"
      ],
      "metadata": {
        "id": "uH69i3rg_VZJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_texts = [clean_text(text) for text in input_texts]\n",
        "target_texts = [clean_text(text) for text in target_texts]"
      ],
      "metadata": {
        "id": "ZCtB33cR_2_Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "\n",
        "def build_vocab(texts):\n",
        "    words = [word for sentence in texts for word in sentence.split()]\n",
        "    word_counts = Counter(words)\n",
        "    vocab = ['<pad>', '<sos>', '<eos>'] + list(word_counts.keys())\n",
        "    word_to_idx = {word: idx for idx, word in enumerate(vocab)}\n",
        "    idx_to_word = {idx: word for word, idx in word_to_idx.items()}\n",
        "    return vocab, word_to_idx, idx_to_word\n",
        "\n",
        "input_vocab, input_word_to_idx, input_idx_to_word = build_vocab(input_texts)\n",
        "target_vocab, target_word_to_idx, target_idx_to_word = build_vocab(target_texts)\n",
        "\n",
        "print(\"Input Vocabulary:\", input_vocab)\n",
        "print(\"Target Vocabulary:\", target_vocab)\n",
        "print('*'*8)\n",
        "print(\"Input Word to Index:\", input_word_to_idx)\n",
        "print(\"Target Word to Index:\", target_word_to_idx)\n",
        "print('*'*8)\n",
        "print(\"Input Index to Word:\", input_idx_to_word)\n",
        "print(\"Target Index to Word:\", target_idx_to_word)\n"
      ],
      "metadata": {
        "id": "5rCGLt49eZoy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78b43fd2-f609-4ba6-bf1f-5f0a2fbe341e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Vocabulary: ['<pad>', '<sos>', '<eos>', 'hi', 'how', 'are', 'you', 'doing', 'im', 'fine', 'about', 'yourself', 'pretty', 'good', 'thanks', 'for', 'asking', 'no', 'problem', 'so', 'have', 'been', 'ive', 'great', 'what', 'in', 'school', 'right', 'now', 'do', 'go', 'to', 'i', 'pcc', 'like', 'it', 'there', 'its', 'okay', 'a', 'really', 'big', 'campus']\n",
            "Target Vocabulary: ['<pad>', '<sos>', '<eos>', 'im', 'fine', 'how', 'about', 'yourself', 'pretty', 'good', 'thanks', 'for', 'asking', 'no', 'problem', 'so', 'have', 'you', 'been', 'ive', 'great', 'what', 'in', 'school', 'right', 'now', 'do', 'go', 'to', 'i', 'pcc', 'like', 'it', 'there', 'its', 'okay', 'a', 'really', 'big', 'campus', 'luck', 'with']\n",
            "********\n",
            "Input Word to Index: {'<pad>': 0, '<sos>': 1, '<eos>': 2, 'hi': 3, 'how': 4, 'are': 5, 'you': 6, 'doing': 7, 'im': 8, 'fine': 9, 'about': 10, 'yourself': 11, 'pretty': 12, 'good': 13, 'thanks': 14, 'for': 15, 'asking': 16, 'no': 17, 'problem': 18, 'so': 19, 'have': 20, 'been': 21, 'ive': 22, 'great': 23, 'what': 24, 'in': 25, 'school': 26, 'right': 27, 'now': 28, 'do': 29, 'go': 30, 'to': 31, 'i': 32, 'pcc': 33, 'like': 34, 'it': 35, 'there': 36, 'its': 37, 'okay': 38, 'a': 39, 'really': 40, 'big': 41, 'campus': 42}\n",
            "Target Word to Index: {'<pad>': 0, '<sos>': 1, '<eos>': 2, 'im': 3, 'fine': 4, 'how': 5, 'about': 6, 'yourself': 7, 'pretty': 8, 'good': 9, 'thanks': 10, 'for': 11, 'asking': 12, 'no': 13, 'problem': 14, 'so': 15, 'have': 16, 'you': 17, 'been': 18, 'ive': 19, 'great': 20, 'what': 21, 'in': 22, 'school': 23, 'right': 24, 'now': 25, 'do': 26, 'go': 27, 'to': 28, 'i': 29, 'pcc': 30, 'like': 31, 'it': 32, 'there': 33, 'its': 34, 'okay': 35, 'a': 36, 'really': 37, 'big': 38, 'campus': 39, 'luck': 40, 'with': 41}\n",
            "********\n",
            "Input Index to Word: {0: '<pad>', 1: '<sos>', 2: '<eos>', 3: 'hi', 4: 'how', 5: 'are', 6: 'you', 7: 'doing', 8: 'im', 9: 'fine', 10: 'about', 11: 'yourself', 12: 'pretty', 13: 'good', 14: 'thanks', 15: 'for', 16: 'asking', 17: 'no', 18: 'problem', 19: 'so', 20: 'have', 21: 'been', 22: 'ive', 23: 'great', 24: 'what', 25: 'in', 26: 'school', 27: 'right', 28: 'now', 29: 'do', 30: 'go', 31: 'to', 32: 'i', 33: 'pcc', 34: 'like', 35: 'it', 36: 'there', 37: 'its', 38: 'okay', 39: 'a', 40: 'really', 41: 'big', 42: 'campus'}\n",
            "Target Index to Word: {0: '<pad>', 1: '<sos>', 2: '<eos>', 3: 'im', 4: 'fine', 5: 'how', 6: 'about', 7: 'yourself', 8: 'pretty', 9: 'good', 10: 'thanks', 11: 'for', 12: 'asking', 13: 'no', 14: 'problem', 15: 'so', 16: 'have', 17: 'you', 18: 'been', 19: 'ive', 20: 'great', 21: 'what', 22: 'in', 23: 'school', 24: 'right', 25: 'now', 26: 'do', 27: 'go', 28: 'to', 29: 'i', 30: 'pcc', 31: 'like', 32: 'it', 33: 'there', 34: 'its', 35: 'okay', 36: 'a', 37: 'really', 38: 'big', 39: 'campus', 40: 'luck', 41: 'with'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_text(text, word_to_idx, max_len=10):\n",
        "    tokens = ['<sos>'] + text.split() + ['<eos>']\n",
        "    token_ids = [word_to_idx.get(word, word_to_idx['<pad>']) for word in tokens]\n",
        "    token_ids += [word_to_idx['<pad>']] * (max_len - len(token_ids))\n",
        "    return torch.tensor(token_ids[:max_len])\n",
        "\n",
        "src_data = torch.stack([encode_text(text, input_word_to_idx) for text in input_texts])\n",
        "tgt_data = torch.stack([encode_text(text, target_word_to_idx) for text in target_texts])\n",
        "\n",
        "print(\"Source Data:\", src_data)\n",
        "print(\"Target Data:\", tgt_data)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pim64rr0edWx",
        "outputId": "3c469918-b219-4b82-9b8c-6ef71e597eda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Source Data: tensor([[ 1,  3,  4,  5,  6,  7,  2,  0,  0,  0],\n",
            "        [ 1,  8,  9,  4, 10, 11,  2,  0,  0,  0],\n",
            "        [ 1,  8, 12, 13, 14, 15, 16,  2,  0,  0],\n",
            "        [ 1, 17, 18, 19,  4, 20,  6, 21,  2,  0],\n",
            "        [ 1, 22, 21, 23, 24, 10,  6,  2,  0,  0],\n",
            "        [ 1, 22, 21, 13,  8, 25, 26, 27, 28,  2],\n",
            "        [ 1, 24, 26, 29,  6, 30, 31,  2,  0,  0],\n",
            "        [ 1, 32, 30, 31, 33,  2,  0,  0,  0,  0],\n",
            "        [ 1, 29,  6, 34, 35, 36,  2,  0,  0,  0],\n",
            "        [ 1, 37, 38, 37, 39, 40, 41, 42,  2,  0]])\n",
            "Target Data: tensor([[ 1,  3,  4,  5,  6,  7,  2,  0,  0,  0],\n",
            "        [ 1,  3,  8,  9, 10, 11, 12,  2,  0,  0],\n",
            "        [ 1, 13, 14, 15,  5, 16, 17, 18,  2,  0],\n",
            "        [ 1, 19, 18, 20, 21,  6, 17,  2,  0,  0],\n",
            "        [ 1, 19, 18,  9,  3, 22, 23, 24, 25,  2],\n",
            "        [ 1, 21, 23, 26, 17, 27, 28,  2,  0,  0],\n",
            "        [ 1, 29, 27, 28, 30,  2,  0,  0,  0,  0],\n",
            "        [ 1, 26, 17, 31, 32, 33,  2,  0,  0,  0],\n",
            "        [ 1, 34, 35, 34, 36, 37, 38, 39,  2,  0],\n",
            "        [ 1,  9, 40, 41, 23,  2,  0,  0,  0,  0]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = TransformerModel(len(input_vocab), len(target_vocab)).to(device)\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=target_word_to_idx['<pad>'])\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n"
      ],
      "metadata": {
        "id": "CFzI8kAuegdi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, src_data, tgt_data, epochs=100):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0\n",
        "        for src, tgt in zip(src_data, tgt_data):\n",
        "            src, tgt = src.unsqueeze(0).to(device), tgt.unsqueeze(0).to(device)\n",
        "            # print(\"Source shape\",src.shape)\n",
        "            # Split target into input and output\n",
        "            tgt_input = tgt[:, :-1]\n",
        "            tgt_output = tgt[:, 1:]\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            output = model(src, tgt_input)\n",
        "            # print(output.shape)\n",
        "            # Reshape for calculating loss\n",
        "            output = output.reshape(-1, len(target_vocab)) # Adjust dimensions so that 2nd dimension is len(targt_vocab)\n",
        "            tgt_output = tgt_output.reshape(-1) # Flatten\n",
        "            # print(output.shape, tgt_output.shape)\n",
        "            loss = criterion(output, tgt_output)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss / len(src_data)}\")\n"
      ],
      "metadata": {
        "id": "447C1G9OekHo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, input_text):\n",
        "    model.eval()\n",
        "    src = encode_text(input_text, input_word_to_idx).unsqueeze(0).to(device)\n",
        "    # print(src.shape)\n",
        "    tgt_input = torch.tensor([[target_word_to_idx['<sos>']]], dtype=torch.long).to(device)\n",
        "\n",
        "    for _ in range(10):\n",
        "        with torch.no_grad():\n",
        "            output = model(src, tgt_input)\n",
        "            # print(output.shape)\n",
        "            next_token_logits = output[:, -1, :]\n",
        "            # print(next_token_logits.shape)\n",
        "            next_token_id = torch.argmax(next_token_logits, dim=-1).item()\n",
        "\n",
        "            if next_token_id == target_word_to_idx['<eos>']:\n",
        "                break\n",
        "\n",
        "            tgt_input = torch.cat([tgt_input, torch.tensor([[next_token_id]], dtype=torch.long).to(device)], dim=1)\n",
        "\n",
        "    result = [target_idx_to_word[idx.item()] for idx in tgt_input[0]]\n",
        "    return ' '.join(result[1:])\n",
        "\n",
        "# Example\n",
        "print(evaluate_model(model, \"hi how are you\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XZ-mIolsepBa",
        "outputId": "f1d23128-91ed-4b85-a285-5f3e6aed9a99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "good for <pad> there have there have there have there\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_model(model, src_data, tgt_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ezo2zHwPerwH",
        "outputId": "a0211393-86e7-4f33-c37d-0873bbb9908a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100, Loss: 3.9007261037826537\n",
            "Epoch 2/100, Loss: 3.5297161102294923\n",
            "Epoch 3/100, Loss: 3.3479026794433593\n",
            "Epoch 4/100, Loss: 3.171660852432251\n",
            "Epoch 5/100, Loss: 2.9848204135894774\n",
            "Epoch 6/100, Loss: 2.827900457382202\n",
            "Epoch 7/100, Loss: 2.6371424198150635\n",
            "Epoch 8/100, Loss: 2.5025051116943358\n",
            "Epoch 9/100, Loss: 2.4049530029296875\n",
            "Epoch 10/100, Loss: 2.2357290744781495\n",
            "Epoch 11/100, Loss: 2.0342037200927736\n",
            "Epoch 12/100, Loss: 1.9803359389305115\n",
            "Epoch 13/100, Loss: 1.712653386592865\n",
            "Epoch 14/100, Loss: 1.6954543948173524\n",
            "Epoch 15/100, Loss: 1.5787148833274842\n",
            "Epoch 16/100, Loss: 1.3269709646701813\n",
            "Epoch 17/100, Loss: 1.2812429785728454\n",
            "Epoch 18/100, Loss: 1.153561520576477\n",
            "Epoch 19/100, Loss: 1.1810798048973083\n",
            "Epoch 20/100, Loss: 1.1622466027736664\n",
            "Epoch 21/100, Loss: 0.9953729748725891\n",
            "Epoch 22/100, Loss: 0.9568857908248901\n",
            "Epoch 23/100, Loss: 0.9276186406612397\n",
            "Epoch 24/100, Loss: 0.8350179433822632\n",
            "Epoch 25/100, Loss: 0.8391339957714081\n",
            "Epoch 26/100, Loss: 0.8965742945671081\n",
            "Epoch 27/100, Loss: 0.8212582290172576\n",
            "Epoch 28/100, Loss: 0.6772562772035599\n",
            "Epoch 29/100, Loss: 0.704947704076767\n",
            "Epoch 30/100, Loss: 0.7178153783082962\n",
            "Epoch 31/100, Loss: 0.7496614456176758\n",
            "Epoch 32/100, Loss: 0.8336056888103485\n",
            "Epoch 33/100, Loss: 0.9122826844453812\n",
            "Epoch 34/100, Loss: 0.6254032373428344\n",
            "Epoch 35/100, Loss: 0.602956908941269\n",
            "Epoch 36/100, Loss: 0.5552742332220078\n",
            "Epoch 37/100, Loss: 0.6087884396314621\n",
            "Epoch 38/100, Loss: 0.5253991544246673\n",
            "Epoch 39/100, Loss: 0.6719443291425705\n",
            "Epoch 40/100, Loss: 0.6255216658115387\n",
            "Epoch 41/100, Loss: 0.5490578070282937\n",
            "Epoch 42/100, Loss: 0.4458700269460678\n",
            "Epoch 43/100, Loss: 0.5030691921710968\n",
            "Epoch 44/100, Loss: 0.392950502038002\n",
            "Epoch 45/100, Loss: 0.5085545450448989\n",
            "Epoch 46/100, Loss: 0.594968244433403\n",
            "Epoch 47/100, Loss: 0.5895230144262313\n",
            "Epoch 48/100, Loss: 0.43369488418102264\n",
            "Epoch 49/100, Loss: 0.45428535640239714\n",
            "Epoch 50/100, Loss: 0.40843827426433565\n",
            "Epoch 51/100, Loss: 0.3777566388249397\n",
            "Epoch 52/100, Loss: 0.5538354411721229\n",
            "Epoch 53/100, Loss: 0.6445376500487328\n",
            "Epoch 54/100, Loss: 0.5737000897526741\n",
            "Epoch 55/100, Loss: 0.48222665637731554\n",
            "Epoch 56/100, Loss: 0.4097545862197876\n",
            "Epoch 57/100, Loss: 0.4475995287299156\n",
            "Epoch 58/100, Loss: 0.5011336520314217\n",
            "Epoch 59/100, Loss: 0.4680922582745552\n",
            "Epoch 60/100, Loss: 0.48677078261971474\n",
            "Epoch 61/100, Loss: 0.4502857133746147\n",
            "Epoch 62/100, Loss: 0.46528912857174876\n",
            "Epoch 63/100, Loss: 0.40132796168327334\n",
            "Epoch 64/100, Loss: 0.421736516058445\n",
            "Epoch 65/100, Loss: 0.36373213231563567\n",
            "Epoch 66/100, Loss: 0.32066976800560953\n",
            "Epoch 67/100, Loss: 0.38410534560680387\n",
            "Epoch 68/100, Loss: 0.36633606925606726\n",
            "Epoch 69/100, Loss: 0.35446051955223085\n",
            "Epoch 70/100, Loss: 0.4006084866821766\n",
            "Epoch 71/100, Loss: 0.2943446792662144\n",
            "Epoch 72/100, Loss: 0.38372448161244394\n",
            "Epoch 73/100, Loss: 0.3746251180768013\n",
            "Epoch 74/100, Loss: 0.27433017268776894\n",
            "Epoch 75/100, Loss: 0.20944810956716536\n",
            "Epoch 76/100, Loss: 0.23479840978980066\n",
            "Epoch 77/100, Loss: 0.4139563500881195\n",
            "Epoch 78/100, Loss: 0.23686181381344795\n",
            "Epoch 79/100, Loss: 0.35489419624209406\n",
            "Epoch 80/100, Loss: 0.382877953723073\n",
            "Epoch 81/100, Loss: 0.2513407148420811\n",
            "Epoch 82/100, Loss: 0.20875653624534607\n",
            "Epoch 83/100, Loss: 0.20950626730918884\n",
            "Epoch 84/100, Loss: 0.18728624954819678\n",
            "Epoch 85/100, Loss: 0.26308721005916597\n",
            "Epoch 86/100, Loss: 0.2010631587356329\n",
            "Epoch 87/100, Loss: 0.1375312700867653\n",
            "Epoch 88/100, Loss: 0.19137279391288758\n",
            "Epoch 89/100, Loss: 0.1979794606566429\n",
            "Epoch 90/100, Loss: 0.17030748762190343\n",
            "Epoch 91/100, Loss: 0.09692992679774762\n",
            "Epoch 92/100, Loss: 0.11019298993051052\n",
            "Epoch 93/100, Loss: 0.17482506223022937\n",
            "Epoch 94/100, Loss: 0.11608722992241383\n",
            "Epoch 95/100, Loss: 0.18454321958124636\n",
            "Epoch 96/100, Loss: 0.16930959597229958\n",
            "Epoch 97/100, Loss: 0.1151813618838787\n",
            "Epoch 98/100, Loss: 0.1126557894051075\n",
            "Epoch 99/100, Loss: 0.1539765341207385\n",
            "Epoch 100/100, Loss: 0.35407714657485484\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(evaluate_model(model, \"hello how are you doing?\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YqKvW9UIey0x",
        "outputId": "57e59e0e-e48f-4b38-c731-f8f36ea50f61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "im fine how about yourself\n"
          ]
        }
      ]
    }
  ]
}